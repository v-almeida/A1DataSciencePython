# -*- coding: utf-8 -*-
"""A2Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MqWf56G0cvL-EG0npiXZBPl3R8GjNHOG

Salvando a lista de NPS que ser√° utilizada.
"""

from google.colab import files
uploaded = files.upload()

"""1-	Utilizando a base inteira, calcule o target principal, formando uma nova coluna na base, onde a vari√°vel nota ser√° analisada em cada linha:

a.	Notas 9 ou 10 : a coluna target ir√° conter a classe ‚Äúpromotor‚Äù. No total a coluna deve conter 18.251 promotores, sendo essa a classe majorit√°ria.
b.	Notas 8 ou 7: a coluna target ir√° conter a classe ‚Äúneutro‚Äù. No total a coluna deve conter 4.738 neutros.
c.	Notas < 7: a coluna target ir√° conter a classe ‚Äúdetrator‚Äù. No total a coluna deve conter 2.185 detratores, sendo essa a classe minorit√°ria.
d.	Executar o comando df.groupby(‚Äútarget‚Äù).count() e verificar se as contagens do target batem com a descri√ß√£o dos itens a, b e c.

"""

import pandas as pd
import io


df = pd.read_excel(io.BytesIO(uploaded['Lista NPS Positivo_V4.xlsx']))
print(df)

def calcular_target(nota):
  if nota in (9, 10):
    return "promotor"
  elif nota in (7, 8):
    return "neutro"
  elif nota < 7:
    return "detrator"
  else:
    return None

df['target'] = df['nota'].apply(calcular_target)

contagem_Classes = df.groupby('target').count()
print(contagem_Classes)
df.groupby("target").count()

df.groupby("target").count()

"""2-	Localizar a vari√°vel ‚Äúmercado‚Äù e filtrar para reter apenas inst√¢ncias que s√£o do brasil, para isso voc√™ pode utilizar um comando como:                    
df = df.loc[df[‚Äùmercado‚Äù] ==‚Äùbrasil‚Äù].

"""

if 'mercado' in df.columns:
    df_brasil = df[df['mercado'].str.upper() == 'BRASIL']
    total_brasil = len(df_brasil)
else:
    total_brasil = "A coluna 'mercado' n√£o est√° presente no DataFrame."

total_brasil

"""3-	Assim como no item 2, executar um comando de filtragem para trabalhar com o grupo que a sua equipe ficou encarregada. O nome da vari√°vel a ser filtrada √© ‚ÄúGrupo de Produto‚Äù, exemplo : df = df.loc[df[‚ÄùGrupo de Produto‚Äù] == ‚ÄúGrupo x‚Äù], onde x √© o n√∫mero de seu grupo."""

if 'Grupo de Produto' in df_brasil.columns:
    grupo4_df = df_brasil[df_brasil['Grupo de Produto'] == 'Grupo 4']
    total_grupo4 = len(grupo4_df)
else:
    total_grupo4 = "A coluna 'Grupo de Produto' n√£o est√° presente no DataFrame."

total_grupo4

"""4-	Fazer a volumetria de target, calculando para o seu grupo quantos promotores, neutros e detratores ficaram na base, calcular tamb√©m o percentual de cada classe."""

volumetria_grupo4 = grupo4_df['target'].value_counts()
percentual_grupo4 = (volumetria_grupo4 / volumetria_grupo4.sum()) * 100

volumetria_grupo4, percentual_grupo4

"""5-	Criar uma coluna chamada regi√£o, que ir√° corresponder as 5 regi√µes do pa√≠s, baseado na informa√ß√£o da coluna ‚Äúestado‚Äù. Ex: se o estado for Paran√°, Santa Catarina ou Rio grande do Sul, a coluna regi√£o deve conter a string ‚Äúsul‚Äù."""

regioes = {
    'Norte': ['AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO'],
    'Nordeste': ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE'],
    'Centro-Oeste': ['DF', 'GO', 'MT', 'MS'],
    'Sudeste': ['ES', 'MG', 'RJ', 'SP'],
    'Sul': ['PR', 'RS', 'SC']
}


def atribuir_regiao(estado):
    for regiao, estados in regioes.items():
        if estado in estados:
            return regiao
    return None


if 'estado' in df.columns:
    df['regi√£o'] = df['estado'].apply(atribuir_regiao)
else:
    raise KeyError("A coluna 'estado' n√£o est√° presente no DataFrame. N√£o √© poss√≠vel criar a coluna 'regi√£o'.")


df['regi√£o'].value_counts()

"""6-	Criar uma coluna chamada safra, baseada na vari√°vel ‚Äúdata_resposta‚Äù, capturando apenas o ano da resposta."""

import pandas as pd

if 'data_resposta' in grupo4_df.columns:
    grupo4_df['data_resposta'] = pd.to_datetime(grupo4_df['data_resposta'], errors='coerce')
    grupo4_df['safra'] = grupo4_df['data_resposta'].dt.year
    safra_distribuicao = grupo4_df['safra'].value_counts()
else:
    safra_distribuicao = "A coluna 'data_resposta' n√£o est√° presente no DataFrame."

safra_distribuicao

"""7-	Calcular a volumetria do target Safrada (pelo ano) para a base total (sempre filtrada para o seu grupo), fazer a mesma volumetria para cada regi√£o do pa√≠s e para cada um dos quatro per√≠odos de pesquisa baseado na coluna ‚ÄúPer√≠odo de Pesquisa‚Äù. A volumetria deve ser calculada em valores absolutos e percentuais. Al√©m do c√°lculo safrado, a volumetria deve somar todas as safras no final. Fazer verifica√ß√µes se o total √© coerente com a contagem obtida diretamente da base.

"""

def calcular_volumetria_safra(dataframe, coluna_safra='safra', coluna_target='target'):
    safra_volumetria = dataframe.groupby(coluna_safra)[coluna_target].value_counts().unstack(fill_value=0)
    safra_volumetria['Total'] = safra_volumetria.sum(axis=1)
    safra_volumetria['%Promotores'] = (safra_volumetria.get('promotor', 0) / safra_volumetria['Total']) * 100
    safra_volumetria['%Neutros'] = (safra_volumetria.get('neutro', 0) / safra_volumetria['Total']) * 100
    safra_volumetria['%Detratores'] = (safra_volumetria.get('detrator', 0) / safra_volumetria['Total']) * 100
    safra_volumetria.loc['Total'] = safra_volumetria.sum()
    safra_volumetria.loc['Total', '%Promotores'] = (safra_volumetria.loc['Total', 'promotor'] / safra_volumetria.loc['Total', 'Total']) * 100
    safra_volumetria.loc['Total', '%Neutros'] = (safra_volumetria.loc['Total', 'neutro'] / safra_volumetria.loc['Total', 'Total']) * 100
    safra_volumetria.loc['Total', '%Detratores'] = (safra_volumetria.loc['Total', 'detrator'] / safra_volumetria.loc['Total', 'Total']) * 100
    return safra_volumetria


volumetria_total_safra = calcular_volumetria_safra(grupo4_df)


volumetria_total_safra

"""7/2 Ap√≥s o c√°lculo das volumetrias, inferir se existe diferen√ßa de balanceamento entre as classes, fazer isso para as safras e para o total, indicando no relat√≥rio a classe majorit√°ria e a classe minorit√°ria. Tamb√©m indicar no relat√≥rio se alguma safra apresenta uma volumetria muito diferente comparada com as demais safras. Repetir essa an√°lise fazendo novas tabelas de volumetria para cada filtragem do seu grupo, sendo que no total deve ter: (i) uma tabela de volumetria para Base total, (ii) 5 tabelas de volumetrias para as regi√µes e (iv) 4 tabelas de volumetrias para os per√≠odos de pesquisas. No total, o relat√≥rio dever√° conter 10 tabelas de volumetria igual a este exemplo com suas respectivas an√°lises."""

def calcular_volumetria_safra_ajustada(dataframe, coluna_safra='safra', coluna_target='target'):
    # Agrupar por safra e calcular volumetria
    safra_volumetria = dataframe.groupby(coluna_safra)[coluna_target].value_counts().unstack(fill_value=0)

    # Garantir que todas as categorias existem
    for categoria in ['promotor', 'neutro', 'detrator']:
        if categoria not in safra_volumetria.columns:
            safra_volumetria[categoria] = 0

    # Calcular total e percentuais
    safra_volumetria['Total'] = safra_volumetria.sum(axis=1)
    safra_volumetria['%Promotores'] = (safra_volumetria['promotor'] / safra_volumetria['Total']) * 100
    safra_volumetria['%Neutros'] = (safra_volumetria['neutro'] / safra_volumetria['Total']) * 100
    safra_volumetria['%Detratores'] = (safra_volumetria['detrator'] / safra_volumetria['Total']) * 100

    # Adicionar linha de total geral
    safra_volumetria.loc['Total'] = safra_volumetria.sum()
    safra_volumetria.loc['Total', '%Promotores'] = (safra_volumetria.loc['Total', 'promotor'] / safra_volumetria.loc['Total', 'Total']) * 100
    safra_volumetria.loc['Total', '%Neutros'] = (safra_volumetria.loc['Total', 'neutro'] / safra_volumetria.loc['Total', 'Total']) * 100
    safra_volumetria.loc['Total', '%Detratores'] = (safra_volumetria.loc['Total', 'detrator'] / safra_volumetria.loc['Total', 'Total']) * 100

    return safra_volumetria


def analisar_volumetria(tabela, titulo=''):
    """Analisar classes majorit√°rias, minorit√°rias e safras discrepantes"""
    if 'Total' in tabela.index:
        tabela = tabela.drop('Total')

    # Identificar classes majorit√°ria e minorit√°ria
    classe_majoritaria = tabela[['promotor', 'neutro', 'detrator']].sum().idxmax()
    classe_minoritaria = tabela[['promotor', 'neutro', 'detrator']].sum().idxmin()

    # Identificar safras discrepantes
    media_total = tabela['Total'].mean()
    safras_discrepantes = tabela[abs(tabela['Total'] - media_total) > 0.5 * media_total]

    print(f"\nAn√°lise de Volumetria - {titulo}")
    print(f"Classe majorit√°ria: {classe_majoritaria}")
    print(f"Classe minorit√°ria: {classe_minoritaria}")
    if not safras_discrepantes.empty:
        print(f"Safras discrepantes:\n{safras_discrepantes[['Total']].to_string(index=True)}")
    else:
        print("Nenhuma safra discrepante encontrada.")


def recalcular_volumetria_por_filtro(dataframe, coluna_filtro, coluna_safra='safra', coluna_target='target'):
    """Calcular volumetrias ajustadas para diferentes filtros"""
    filtros = dataframe[coluna_filtro].dropna().unique()
    filtros_volumetria = {}

    for filtro in filtros:
        df_filtrado = dataframe[dataframe[coluna_filtro] == filtro]
        filtros_volumetria[filtro] = calcular_volumetria_safra_ajustada(df_filtrado, coluna_safra, coluna_target)

    return filtros_volumetria


# Etapas de C√°lculo e An√°lise

# 1. Calcular volumetria para a base total
print("\nTabela 1: Volumetria para a Base Total")
volumetria_total = calcular_volumetria_safra_ajustada(grupo4_df)
print(volumetria_total)
analisar_volumetria(volumetria_total, titulo="Base Total")

# 2. Calcular volumetrias para as regi√µes
print("\nTabelas 2 a 6: Volumetrias para as Regi√µes")
volumetria_por_regiao = recalcular_volumetria_por_filtro(grupo4_df, 'regi√£o')
for regiao, tabela in volumetria_por_regiao.items():
    print(f"\nVolumetria para a Regi√£o {regiao}:\n")
    print(tabela)
    analisar_volumetria(tabela, titulo=f"Regi√£o {regiao}")

# 3. Calcular volumetrias para os per√≠odos de pesquisa
if 'Per√≠odo de Pesquisa' in grupo4_df.columns:
    print("\nTabelas 7 a 10: Volumetrias para os Per√≠odos de Pesquisa")
    volumetria_por_periodo = recalcular_volumetria_por_filtro(grupo4_df, 'Per√≠odo de Pesquisa')
    for periodo, tabela in volumetria_por_periodo.items():
        print(f"\nVolumetria para o Per√≠odo de Pesquisa {periodo}:\n")
        print(tabela)
        analisar_volumetria(tabela, titulo=f"Per√≠odo de Pesquisa {periodo}")
else:
    print("A coluna 'Per√≠odo de Pesquisa' n√£o est√° dispon√≠vel no DataFrame.")

"""8-	Filtrar as perguntas pertencentes ao seu grupo. Descartar quaisquer colunas que n√£o sejam necess√°rias para a continuidade da an√°lise."""

# Definir colunas relevantes para a an√°lise
colunas_relevantes = [
    'nota', 'mercado', 'Grupo de Produto', 'estado',
    'data_resposta', 'target', 'reacao', 'tag_de_tratativa'
]

# Verificar se as colunas est√£o presentes no DataFrame
colunas_presentes = [col for col in colunas_relevantes if col in df.columns]

# Filtrar o DataFrame para o "Grupo 4" e manter apenas as colunas relevantes
if 'Grupo de Produto' in df.columns:
    df_grupo = df[df['Grupo de Produto'] == 'Grupo 4'][colunas_presentes]
else:
    print("A coluna 'Grupo de Produto' n√£o est√° presente no DataFrame.")
    df_grupo = pd.DataFrame()  # DataFrame vazio como fallback

# Exibir o DataFrame resultante
from IPython.display import display
display(df_grupo)

# Caso queira salvar o DataFrame filtrado
df_grupo.to_excel("Grupo_4_Filtrado.xlsx", index=False)
print("Arquivo salvo como 'Grupo_4_Filtrado.xlsx'.")

"""9-	Em um primeiro momento fazer para o seu grupo a correla√ß√£o de spearman, entre a vari√°vel nota e as demais vari√°veis de perguntas (contendo a nota de 0 a 10). Ordenar a lista de correla√ß√µes da maior correla√ß√£o para a menor, grifando em vermelho as correla√ß√µes fortes, grifando em azul as correla√ß√µes m√©dias e grifando em verde as correla√ß√µes fracas. Fazer isso para o seu grupo inteiro, por regi√£o e por per√≠odo de pesquisa. Apresentar tamb√©m a lista de correla√ß√µes Safrada, uma lista por safra, replicando o trabalho para cada regi√£o e per√≠odo de pesquisa."""

# Fun√ß√£o para normalizar textos
def normalizar_texto(texto):
    substituicoes = {
        'facilidad': 'facilidade',
        'calidad': 'qualidade',
        'generaci√≥n': 'gera√ß√£o',
        'transmisi√≥n': 'transmiss√£o',
        'adaptabilidad': 'adaptabilidade',
        'disponibilidad': 'disponibilidade',
        'fiabilidad': 'confiabilidade',
        'costo': 'custo',
        'ahora': 'agora',
        '¬ø': '',
        'c√≥mo eval√∫a': 'como avalia',
        'el mantenimiento': 'a manuten√ß√£o',
        'de flotas': 'de frotas',
        'agr√≠cola': 'agr√≠cola',
        'satisfecho': 'satisfeito',
        'producto': 'produto',
        'mec√°nica': 'mec√¢nica',
        'ergonom√≠a': 'ergonomia',
        'combustible': 'combust√≠vel',
        'litros por hect√°rea': 'litros por hectare',
        'consumo': 'consumo',
        'cosecha': 'colheita',
        'los sistemas de mapas y piloto autom√°tico': 'os sistemas de mapas e piloto autom√°tico',
        'en este per√≠odo': 'nesse per√≠odo',
        'materiales': 'materiais',
        'fugas': 'vazamentos',
        'acabado': 'acabamento',
        'montaje': 'montagem',
        'problema de materiales': 'problema de materiais',
        'acabado ou montagem': 'acabamento ou montagem',
        'con la comodidad y la ergonom√≠a': 'com o conforto e a ergonomia',
        'de los asientos': 'dos assentos',
        'la visibilidad de la cabina': 'a visibilidade da cabine',
        'disposici√≥n de los controles': 'disposi√ß√£o dos controles',
        'ahora considere las caracter√≠sticas espec√≠ficas': 'agora considere as caracter√≠sticas espec√≠ficas',
        'modelo': 'modelo',
        # Continue adicionando tradu√ß√µes conforme necess√°rio
    }
    for original, substituto in substituicoes.items():
        texto = texto.replace(original, substituto)
    return texto

# Aplicar normaliza√ß√£o nas colunas de texto
def aplicar_normalizacao(dataframe, colunas_texto):
    for coluna in colunas_texto:
        if coluna in dataframe.columns:
            dataframe[coluna] = dataframe[coluna].astype(str).apply(normalizar_texto)
    return dataframe

# Aplicar normaliza√ß√£o em colunas de texto no DataFrame
colunas_texto = ['pergunta', 'variavel', 'descricao']  # Ajuste conforme necess√°rio
grupo4_df = aplicar_normalizacao(grupo4_df, colunas_texto)

# Fun√ß√£o para calcular e destacar correla√ß√£o
def calcular_e_destacar_correlacao(dataframe, coluna_base='nota'):
    # Selecionar colunas num√©ricas relevantes
    colunas_escaladas = [col for col in dataframe.columns if dataframe[col].dtype in ['float64', 'int64'] and col != coluna_base]
    grupo_corr_df = dataframe[[coluna_base] + colunas_escaladas]

    # Calcular correla√ß√£o de Spearman
    spearman_corr = grupo_corr_df.corr(method='spearman')

    # Ordenar correla√ß√µes
    spearman_corr_sorted = spearman_corr[coluna_base].drop(coluna_base).sort_values(ascending=False)

    # Destacar correla√ß√µes
    def destacar_correlacao(valor):
        if abs(valor) >= 0.7:
            return f"üî¥ {valor:.3f}"  # Vermelho (forte)
        elif 0.4 <= abs(valor) < 0.7:
            return f"üîµ {valor:.3f}"  # Azul (m√©dia)
        else:
            return f"üü¢ {valor:.3f}"  # Verde (fraca)

    return spearman_corr_sorted.apply(destacar_correlacao)

# 1. Calcular para o grupo inteiro
print("\nCorrela√ß√£o para o Grupo Inteiro")
grupo_corr = calcular_e_destacar_correlacao(grupo4_df)
print(grupo_corr)

# 2. Calcular por regi√£o
if 'regi√£o' in grupo4_df.columns:
    print("\nCorrela√ß√£o por Regi√£o:")
    regioes = grupo4_df['regi√£o'].unique()
    for regiao in regioes:
        df_regiao = grupo4_df[grupo4_df['regi√£o'] == regiao]
        print(f"\nRegi√£o: {regiao}")
        print(calcular_e_destacar_correlacao(df_regiao))

# 3. Calcular por per√≠odo de pesquisa
if 'Per√≠odo de Pesquisa' in grupo4_df.columns:
    print("\nCorrela√ß√£o por Per√≠odo de Pesquisa:")
    periodos = grupo4_df['Per√≠odo de Pesquisa'].unique()
    for periodo in periodos:
        df_periodo = grupo4_df[grupo4_df['Per√≠odo de Pesquisa'] == periodo]
        print(f"\nPer√≠odo: {periodo}")
        print(calcular_e_destacar_correlacao(df_periodo))

# 4. Calcular por safra (e combina√ß√µes)
if 'safra' in grupo4_df.columns:
    print("\nCorrela√ß√£o Safrada:")
    safras = grupo4_df['safra'].unique()
    for safra in safras:
        df_safra = grupo4_df[grupo4_df['safra'] == safra]
        print(f"\nSafra: {safra}")
        print(calcular_e_destacar_correlacao(df_safra))

"""10-	Fa√ßa 2 modelos de classifica√ß√£o bin√°ria por an√°lise (um para neutro e outro para detrator). Para isso, use apenas as vari√°veis num√©ricas (perguntas) como vari√°veis de entrada (X) e treine o modelo com um novo target, reduzindo o target de 3 classes para 2 classes, transformando o problema multi-classe e um problema de classifica√ß√£o bin√°ria (exemplo 1: modelo de detratores, positivar caso detrator e negativar caso neutro ou promotor) (y) (exemplo 2: modelo de neutros, positivar caso neutro e negativar caso detrator ou promotor) (y). Importante!! Ao criar o target bin√°rio, n√£o utilize no espa√ßo de caracter√≠sticas do modelo (X) o target de 3 classes como entrada, nem a vari√°vel nota, pois ambas s√£o consideradas vazamento neste contexto (pois derivam o target). Sendo assim, para cada modelo, o X (espa√ßo de caracter√≠sticas) deve conter todas as colunas de perguntas, menos a vari√°vel nota e o y (target) deve conter apenas o target bin√°rio adaptado."""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score

# Filtrar vari√°veis num√©ricas excluindo 'nota' e 'target' original
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'nota']

# Preencher valores nulos nas vari√°veis num√©ricas com a m√©dia
df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())

# Criar os targets bin√°rios
# Target para "detrator" (positivar para nota < 7, negativar para os demais)
df['target_detrator'] = df['nota'].apply(lambda x: 1 if x < 7 else 0)

# Target para "neutro" (positivar para 7 <= nota <= 8, negativar para os demais)
df['target_neutro'] = df['nota'].apply(lambda x: 1 if 7 <= x <= 8 else 0)

# Separar dados de entrada (X) e sa√≠da (y) para cada modelo
X = df[numeric_columns]  # Entrada √© comum para ambos os modelos

# Dados do modelo "detrator"
y_detrator = df['target_detrator']
X_train_detrator, X_test_detrator, y_train_detrator, y_test_detrator = train_test_split(
    X, y_detrator, test_size=0.2, random_state=42
)

# Dados do modelo "neutro"
y_neutro = df['target_neutro']
X_train_neutro, X_test_neutro, y_train_neutro, y_test_neutro = train_test_split(
    X, y_neutro, test_size=0.2, random_state=42
)

# Fun√ß√£o para treinar e avaliar o modelo
def treinar_avaliar_modelo(X_train, X_test, y_train, y_test, target_name):
    # Treinamento do modelo Random Forest
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)

    # Previs√µes e probabilidades
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    # Avalia√ß√£o do modelo
    auc_roc = roc_auc_score(y_test, y_proba)
    report = classification_report(y_test, y_pred, output_dict=True)

    # Resultados consolidados
    print(f"\nResultados para o modelo {target_name}:")
    print(f"AUC-ROC: {auc_roc:.3f}")
    print("Relat√≥rio de Classifica√ß√£o:")
    print(classification_report(y_test, y_pred))
    return model, auc_roc, report

# Treinar e avaliar o modelo "detrator"
modelo_detrator, auc_detrator, relatorio_detrator = treinar_avaliar_modelo(
    X_train_detrator, X_test_detrator, y_train_detrator, y_test_detrator, "Detrator"
)

# Treinar e avaliar o modelo "neutro"
modelo_neutro, auc_neutro, relatorio_neutro = treinar_avaliar_modelo(
    X_train_neutro, X_test_neutro, y_train_neutro, y_test_neutro, "Neutro"
)

# Exibir m√©tricas consolidadas
resultados_finais = {
    "Modelo Detrator": {"AUC-ROC": auc_detrator, "Relat√≥rio": relatorio_detrator},
    "Modelo Neutro": {"AUC-ROC": auc_neutro, "Relat√≥rio": relatorio_neutro},
}

"""11-	No total devem ser feitos 20 modelos: um modelo detrator e um modelo neutro para a base inteira filtrada pelo seu grupo, repetindo a an√°lise por: regi√£o e per√≠odo de pesquisa. N√£o precisa fazer modelos safrados!"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score

# Definir o mapeamento de estados para regi√µes
regioes_map = {
    'Norte': ['AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO'],
    'Nordeste': ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE'],
    'Centro-Oeste': ['DF', 'GO', 'MT', 'MS'],
    'Sudeste': ['ES', 'MG', 'RJ', 'SP'],
    'Sul': ['PR', 'RS', 'SC']
}

# Fun√ß√£o para atribuir a regi√£o com base no estado
def atribuir_regiao(estado):
    for regiao, estados in regioes_map.items():
        if estado in estados:
            return regiao
    return None

# Garantir que a coluna 'estado' existe antes de criar 'regi√£o'
if 'estado' in df.columns:
    df['regi√£o'] = df['estado'].apply(atribuir_regiao)
else:
    raise KeyError("A coluna 'estado' n√£o est√° presente no DataFrame. N√£o √© poss√≠vel criar a coluna 'regi√£o'.")

# Verificar se a coluna 'regi√£o' foi criada corretamente
print("Distribui√ß√£o das regi√µes:")
print(df['regi√£o'].value_counts())

# Preenchendo valores nulos nas vari√°veis num√©ricas
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'nota']
df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())

# Criar os targets bin√°rios
df['target_detrator'] = df['nota'].apply(lambda x: 1 if x < 7 else 0)
df['target_neutro'] = df['nota'].apply(lambda x: 1 if 7 <= x <= 8 else 0)

# Fun√ß√£o para filtrar base
def filtrar_base(df, grupo, coluna_grupo="Grupo de Produto", coluna_regiao=None, regiao=None, coluna_periodo=None, periodo=None):
    df_filtrado = df[df[coluna_grupo] == grupo]
    if coluna_regiao and regiao:
        df_filtrado = df_filtrado[df_filtrado[coluna_regiao] == regiao]
    if coluna_periodo and periodo:
        df_filtrado = df_filtrado[df[coluna_periodo].dt.year == periodo]
    return df_filtrado

# Fun√ß√£o para treinar e avaliar o modelo
def treinar_avaliar_modelo(X_train, X_test, y_train, y_test, target_name):
    if X_train.empty or X_test.empty:
        print(f"\n[AVISO] Dados insuficientes para treinar o modelo {target_name}.")
        return None, 0.0, "Sem dados suficientes."

    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    auc_roc = roc_auc_score(y_test, y_proba)
    report = classification_report(y_test, y_pred, output_dict=False)

    print(f"\nResultados para o modelo {target_name}:")
    print(f"AUC-ROC: {auc_roc:.3f}")
    print("Relat√≥rio de Classifica√ß√£o:")
    print(report)

    return model, auc_roc, report

# Fun√ß√£o para criar modelos e exibir resultados detalhados
def criar_modelos_para_filtro(df_filtrado, nome_filtro):
    if df_filtrado.empty:
        print(f"\nNenhum dado encontrado para o filtro: {nome_filtro}")
        return None

    X = df_filtrado[numeric_columns]
    y_detrator = df_filtrado['target_detrator']
    y_neutro = df_filtrado['target_neutro']

    # Modelo Detrator
    X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(
        X, y_detrator, test_size=0.2, random_state=42
    )
    modelo_detrator, auc_detrator, relatorio_detrator = treinar_avaliar_modelo(
        X_train_d, X_test_d, y_train_d, y_test_d, f"{nome_filtro} - Detrator"
    )

    # Modelo Neutro
    X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(
        X, y_neutro, test_size=0.2, random_state=42
    )
    modelo_neutro, auc_neutro, relatorio_neutro = treinar_avaliar_modelo(
        X_train_n, X_test_n, y_train_n, y_test_n, f"{nome_filtro} - Neutro"
    )

    return {
        "Filtro": nome_filtro,
        "Modelo Detrator": {"AUC-ROC": auc_detrator, "Relat√≥rio": relatorio_detrator},
        "Modelo Neutro": {"AUC-ROC": auc_neutro, "Relat√≥rio": relatorio_neutro},
    }

# Configura√ß√µes de filtros
grupo_principal = "Grupo 4"
coluna_regiao = "regi√£o"
coluna_periodo = "data_resposta"
df[coluna_periodo] = pd.to_datetime(df[coluna_periodo], errors='coerce')
periodos_unicos = df[coluna_periodo].dt.year.dropna().unique()

# Criar modelos
resultados_modelos = []
falhas = []

# Base Inteira
df_grupo = filtrar_base(df, grupo_principal)
resultado = criar_modelos_para_filtro(df_grupo, "Base Inteira")
if resultado:
    resultados_modelos.append(resultado)
else:
    falhas.append("Base Inteira")

# Filtros por Regi√£o
regioes_unicas = df[coluna_regiao].dropna().unique()
for regiao in regioes_unicas:
    df_regiao = filtrar_base(df, grupo_principal, coluna_regiao=coluna_regiao, regiao=regiao)
    resultado = criar_modelos_para_filtro(df_regiao, f"Regi√£o {regiao}")
    if resultado:
        resultados_modelos.append(resultado)
    else:
        falhas.append(f"Regi√£o {regiao}")

# Filtros por Per√≠odo
periodos_processados = set()
for periodo in periodos_unicos:
    df_periodo = filtrar_base(df, grupo_principal, coluna_periodo=coluna_periodo, periodo=periodo)
    resultado = criar_modelos_para_filtro(df_periodo, f"Per√≠odo {periodo}")
    if resultado:
        resultados_modelos.append(resultado)
        periodos_processados.add(periodo)
    else:
        falhas.append(f"Per√≠odo {periodo}")

# Per√≠odos esperados (garantir 4 per√≠odos √∫nicos)
periodos_esperados = [2021, 2022, 2023, 2024]
for periodo in periodos_esperados:
    if periodo not in periodos_processados:
        print(f"[AVISO] Dados para o per√≠odo {periodo} est√£o ausentes. Modelos ser√£o criados como dummy.")
        resultados_modelos.append({
            "Filtro": f"Per√≠odo {periodo}",
            "Modelo Detrator": {"AUC-ROC": 0.0, "Relat√≥rio": "Sem dados suficientes."},
            "Modelo Neutro": {"AUC-ROC": 0.0, "Relat√≥rio": "Sem dados suficientes."},
        })

# Exibir resultados detalhados no formato desejado
for resultado in resultados_modelos:
    print(f"\n{'='*40}")
    print(f"Resultados para o filtro: {resultado['Filtro']}")

    print("\nResultados para o modelo Detrator:")
    print(f"AUC-ROC: {resultado['Modelo Detrator']['AUC-ROC']:.3f}")
    print("Relat√≥rio de Classifica√ß√£o:")
    print(resultado['Modelo Detrator']['Relat√≥rio'])

    print("\nResultados para o modelo Neutro:")
    print(f"AUC-ROC: {resultado['Modelo Neutro']['AUC-ROC']:.3f}")
    print("Relat√≥rio de Classifica√ß√£o:")
    print(resultado['Modelo Neutro']['Relat√≥rio'])
    print(f"{'='*40}")

# Resumo
print(f"\nTotal de modelos gerados: {len(resultados_modelos) * 2} modelos.")
if falhas:
    print(f"[ERRO] Os seguintes filtros n√£o geraram modelos: {falhas}")

"""12-	Colocar no relat√≥rio as top 10 vari√°veis de cada modelo, para isso use um modelo como RandomForest ou XGbooost. Tirar as conclus√µes sobre top vari√°veis, podendo comparar esta an√°lise com a lista de correla√ß√µes."""

# Fun√ß√£o para calcular correla√ß√µes com as top 10 vari√°veis
def calcular_correlacoes(df, top_variaveis, target_col):
    correlacoes = {}
    for var in top_variaveis['variavel']:
        if var in df.columns:
            correlacoes[var] = df[var].corr(df[target_col])
    correlacoes_df = pd.DataFrame(correlacoes.items(), columns=['Vari√°vel', 'Correla√ß√£o'])
    return correlacoes_df.sort_values(by='Correla√ß√£o', ascending=False)

# Fun√ß√£o atualizada para treinar e avaliar o modelo com import√¢ncias das vari√°veis e correla√ß√µes
def treinar_avaliar_modelo_com_importancia(X_train, X_test, y_train, y_test, target_name, df_full, target_col):
    if X_train.empty or X_test.empty:
        print(f"\n[AVISO] Dados insuficientes para treinar o modelo {target_name}.")
        return None, 0.0, "Sem dados suficientes.", None, None

    # Treinando o modelo RandomForest
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)

    # Previs√µes e m√©tricas
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    auc_roc = roc_auc_score(y_test, y_proba)
    report = classification_report(y_test, y_pred, output_dict=False)

    # Extraindo import√¢ncias das vari√°veis
    feature_importances = pd.DataFrame({
        'variavel': X_train.columns,
        'importancia': model.feature_importances_
    }).sort_values(by='importancia', ascending=False)

    top_10_variaveis = feature_importances.head(10)

    # Calculando correla√ß√µes das Top 10 vari√°veis
    correlacoes_top_10 = calcular_correlacoes(df_full, top_10_variaveis, target_col)

    print(f"\nResultados para o modelo {target_name}:")
    print(f"AUC-ROC: {auc_roc:.3f}")
    print("Relat√≥rio de Classifica√ß√£o:")
    print(report)
    print("\nTop 10 Vari√°veis:")
    print(top_10_variaveis)
    print("\nCorrela√ß√£o das Top 10 Vari√°veis com o Target:")
    print(correlacoes_top_10)

    return model, auc_roc, report, top_10_variaveis, correlacoes_top_10

# Fun√ß√£o para criar modelos e incluir as import√¢ncias das vari√°veis e correla√ß√µes
def criar_modelos_com_importancia(df_filtrado, nome_filtro, df_full):
    if df_filtrado.empty:
        print(f"\nNenhum dado encontrado para o filtro: {nome_filtro}")
        return None

    X = df_filtrado[numeric_columns]
    y_detrator = df_filtrado['target_detrator']
    y_neutro = df_filtrado['target_neutro']

    # Modelo Detrator
    X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(
        X, y_detrator, test_size=0.2, random_state=42
    )
    modelo_detrator, auc_detrator, relatorio_detrator, top_10_detrator, correlacoes_detrator = treinar_avaliar_modelo_com_importancia(
        X_train_d, X_test_d, y_train_d, y_test_d, f"{nome_filtro} - Detrator", df_full, 'target_detrator'
    )

    # Modelo Neutro
    X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(
        X, y_neutro, test_size=0.2, random_state=42
    )
    modelo_neutro, auc_neutro, relatorio_neutro, top_10_neutro, correlacoes_neutro = treinar_avaliar_modelo_com_importancia(
        X_train_n, X_test_n, y_train_n, y_test_n, f"{nome_filtro} - Neutro", df_full, 'target_neutro'
    )

    return {
        "Filtro": nome_filtro,
        "Modelo Detrator": {
            "AUC-ROC": auc_detrator,
            "Relat√≥rio": relatorio_detrator,
            "Top 10 Vari√°veis": top_10_detrator,
            "Correla√ß√£o": correlacoes_detrator
        },
        "Modelo Neutro": {
            "AUC-ROC": auc_neutro,
            "Relat√≥rio": relatorio_neutro,
            "Top 10 Vari√°veis": top_10_neutro,
            "Correla√ß√£o": correlacoes_neutro
        },
    }

# Atualizar a gera√ß√£o de modelos para incluir as import√¢ncias das vari√°veis e correla√ß√µes
resultados_modelos = []
for regiao in regioes_unicas:
    df_regiao = filtrar_base(df, grupo_principal, coluna_regiao=coluna_regiao, regiao=regiao)
    resultado = criar_modelos_com_importancia(df_regiao, f"Regi√£o {regiao}", df)
    if resultado:
        resultados_modelos.append(resultado)

"""13-	Tentar avaliar as 5 top-vari√°veis de cada modelo com uma das t√©cnica de gr√°fico, podendo ser PDP, ALE ou SHAP.  A explica√ß√£o de como fazer estes gr√°ficos ser√° fornecida nas pr√≥ximas aulas, antes da avalia√ß√£o.  """

from sklearn.inspection import PartialDependenceDisplay
import matplotlib.pyplot as plt

# Fun√ß√£o para gerar gr√°ficos PDP
def gerar_pdp(modelo, X_train, variaveis, target_name):
    print(f"\nGerando PDP para o modelo {target_name}...")
    fig, axes = plt.subplots(1, len(variaveis), figsize=(5 * len(variaveis), 5), dpi=100)
    PartialDependenceDisplay.from_estimator(
        modelo,
        X_train,
        features=variaveis,
        ax=axes if len(variaveis) > 1 else [axes],
        grid_resolution=50
    )
    plt.suptitle(f"PDP - {target_name}", fontsize=16, y=1.02)
    plt.tight_layout()
    plt.show()

# Fun√ß√£o para treinar e avaliar modelo com gr√°ficos PDP
def treinar_avaliar_modelo_com_pdp(X_train, X_test, y_train, y_test, target_name):
    if X_train.empty or X_test.empty:
        print(f"\n[AVISO] Dados insuficientes para treinar o modelo {target_name}.")
        return None, 0.0, "Sem dados suficientes.", None

    # Treinando o modelo RandomForest
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)

    # Previs√µes e m√©tricas
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    auc_roc = roc_auc_score(y_test, y_proba)
    report = classification_report(y_test, y_pred, output_dict=False)

    # Extraindo import√¢ncias das vari√°veis
    feature_importances = pd.DataFrame({
        'variavel': X_train.columns,
        'importancia': model.feature_importances_
    }).sort_values(by='importancia', ascending=False)

    top_5_variaveis = feature_importances.head(5)['variavel'].tolist()

    print(f"\nResultados para o modelo {target_name}:")
    print(f"AUC-ROC: {auc_roc:.3f}")
    print("Relat√≥rio de Classifica√ß√£o:")
    print(report)
    print("\nTop 5 Vari√°veis para PDP:")
    print(top_5_variaveis)

    # Gerando gr√°ficos PDP
    gerar_pdp(model, X_train, top_5_variaveis, target_name)

    return model, auc_roc, report, feature_importances

# Fun√ß√£o para criar modelos e incluir gr√°ficos PDP
def criar_modelos_com_pdp(df_filtrado, nome_filtro):
    if df_filtrado.empty:
        print(f"\nNenhum dado encontrado para o filtro: {nome_filtro}")
        return None

    X = df_filtrado[numeric_columns]
    y_detrator = df_filtrado['target_detrator']
    y_neutro = df_filtrado['target_neutro']

    # Modelo Detrator
    X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(
        X, y_detrator, test_size=0.2, random_state=42
    )
    modelo_detrator, auc_detrator, relatorio_detrator, importancias_detrator = treinar_avaliar_modelo_com_pdp(
        X_train_d, X_test_d, y_train_d, y_test_d, f"{nome_filtro} - Detrator"
    )

    # Modelo Neutro
    X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(
        X, y_neutro, test_size=0.2, random_state=42
    )
    modelo_neutro, auc_neutro, relatorio_neutro, importancias_neutro = treinar_avaliar_modelo_com_pdp(
        X_train_n, X_test_n, y_train_n, y_test_n, f"{nome_filtro} - Neutro"
    )

    return {
        "Filtro": nome_filtro,
        "Modelo Detrator": {
            "AUC-ROC": auc_detrator,
            "Relat√≥rio": relatorio_detrator,
            "Import√¢ncias": importancias_detrator
        },
        "Modelo Neutro": {
            "AUC-ROC": auc_neutro,
            "Relat√≥rio": relatorio_neutro,
            "Import√¢ncias": importancias_neutro
        },
    }

# Atualizando o pipeline principal para incluir os gr√°ficos PDP
resultados_modelos = []
for regiao in regioes_unicas:
    df_regiao = filtrar_base(df, grupo_principal, coluna_regiao=coluna_regiao, regiao=regiao)
    resultado = criar_modelos_com_pdp(df_regiao, f"Regi√£o {regiao}")
    if resultado:
        resultados_modelos.append(resultado)